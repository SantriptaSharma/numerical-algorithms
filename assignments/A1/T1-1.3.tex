We can see the results of the iteration here:

\begin{center}
	\includegraphics*[width=0.8\textwidth]{res/1.3-convergence.png}
\end{center}

and the abs error (against the best approximation of $\sqrt{2}$ available on my computer):

\begin{center}
	\includegraphics*[width=0.8\textwidth]{res/1.3-error.png}
\end{center}

This figure confirms, and gives us a better intuition for, the quadratic convergence rate. We see that the error term is squared at each iteration (due to the derivative of the FPI being 0 at the fixed point, $\sqrt{2}$).\bigskip

To formalise this, define the order of an error term $e_i$ as the smallest power of 10, $10^o$, such that $e_i < 10^{o + 1}$.\medskip

If the initial error was of the order of $10^{-1}$ (which is the case for $x_0 = 1, e_0 = 0.41\dots$, since they differ in all digits $10^{-1}$ onwards), the error after $t$ iterations, $e_t$, is of the order $10^{-2^t}$. If $d$ is the desired digits of precision, making the replacement $t = \log d \Rightarrow e_t$ is of the order $10^{-2^{\log d}} = 10^{-d}$. Therefore, after $\log d$ iterations, the error is bounded above by $10^{-d + 1}$, which gives us (roughly) the desired precision. 
